# HaufeInternship2025
Trying to create and implement LLM with ollama , Fast API , and local servers
